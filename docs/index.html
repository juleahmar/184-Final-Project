<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Final Project: Milestone Progress Report</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2019</h1>
<h1 align="middle">Final Project Milestone Progress Report</h1>
<h2 align="middle">Nathan Petreaca (3033319031), Frankie Eder (3032702792), Jule Ahmar (3031851720)</h2>

<div>

<h2 align="middle">Overview</h2>
<p> As stated in our original project proposal, our goal is to add CG objects into a photograph, while preserving the actual lighting from the scene. We are essentially attempting to recreate, and basing our work from, “Rendering Synthetic Objects into Real Scenes: Bridging Traditional and Image-based Graphics with Global Illumination and High Dynamic Range Photography“, a 1998 paper by Paul Debevec. Just as in the paper, our light probe will be a mirrored sphere ball, and we will capture the light falling on the ball via a camera calibration method.</p>

<h2 align="middle">Preliminary Results</h2>

<p>The first step we took in this project was taking the necessary HDR images of various scenes, using a light probe to capture all of the environment light. As previously discussed, we used a stainless steel mirrored ball sphere as our light probe. We then made EXR environment maps out of the images of these balls for later use in adding CG objects to the scenes. Finally, we created an algorithm to visualize response curves, and did tone mapping for viewing.  </p>

<h2 align="middle">Progress Relative to Plan</h2>

<p>In our original project writeup, we had the following goals for our 2 week checkpoint: <br>
	&nbsp;- HDR images <br>
	&nbsp;&nbsp;&nbsp;1. Collect images <br>
	&nbsp;&nbsp;&nbsp;2. Implement Code <br>
	&nbsp;&nbsp;&nbsp;3. Create error reduction algorithm to generate response curves <br>
	&nbsp;&nbsp;&nbsp;4. Tone map images for viewing. <br> <br>

	And had the following goals for Week 3: <br>
	&nbsp;- Correct environment maps from mirrored sphere <br>
	&nbsp;&nbsp;&nbsp;1. Create correct mapping scheme from circular coordinates <br>
	&nbsp;&nbsp;&nbsp;2.  Implement differential rendering to improve speed <br> <br>

	At this point we have completed all of our goals for our 2 week checkpoint, and have also made significant progress in our week three goal of creating EXR environment maps out of our images of the light probe. We are able to get these by using the algorithm described in the paper by Paul Debevec. This consists of mapping our circular image to a rectangular one, then creating a panorama by doing a latitude/longitude mapping.
</p>

<h2 align="middle">Updated Work Plan</h2>

<p>At this point in time, our work plan has not changed. We are on track with where we believed we would be, if not a little bit ahead. As a result, we should have more time to focus on the most substantial and compelling part of the project, which consists of actually adding CG objects to the scene.</p>


<h2 align="middle">Slides/Video Links</h2>

<p>Slides: <a href= "https://docs.google.com/presentation/d/18pzdvvusuEkUP5mUu4lpO1yOwYpvuGtPsM4-PU5HU2g/edit#slide=id.p"> here</a> <br>

  Video:  <a href= "https://www.youtube.com/watch?v=90ELzBYq3Xo&fbclid=IwAR1IDcvmoFBUbrI3-1vkudOaqo4LQHWATY4nFRbUQOXc1wLKnfEuZ-kebzo"> here</a> <br>

</p>

</body>
</html>
